import numpy as np

def build_specialist_set(features_set, labels_set, specialist_class):
    class_features = []
    no_class_features = []

    for i, label in enumerate(labels_set):
        if label == specialist_class:
            class_features.append(features_set[i])
        else:
            no_class_features.append(features_set[i])

    # Verifica se alguma lista estÃ¡ vazia e trata adequadamente
    if len(class_features) == 0 and len(no_class_features) == 0:
        raise ValueError(f"Nenhum dado encontrado para a classe {specialist_class}")
    
    if len(class_features) == 0:
        # Se nÃ£o hÃ¡ exemplares da classe, retorna apenas os dados de "nÃ£o-classe"
        no_class_features = np.array(no_class_features)
        no_class_labels = np.array([1] * len(no_class_features))
        print("=" * 15)
        print(f"AVISO: Classe {specialist_class} nÃ£o possui exemplares!")
        print("Retornando apenas dados de nÃ£o-classe")
        print(f"No class features shape: {no_class_features.shape}")
        print(f"No class labels shape: {no_class_labels.shape}")
        print("=" * 15)
        return (no_class_features, no_class_labels)
    
    if len(no_class_features) == 0:
        # Se nÃ£o hÃ¡ exemplares de outras classes, retorna apenas os dados da classe
        class_features = np.array(class_features)
        class_labels = np.array([0] * len(class_features))
        print("=" * 15)
        print(f"AVISO: Apenas classe {specialist_class} possui exemplares!")
        print(f"Class features shape: {class_features.shape}")
        print(f"Class labels shape: {class_labels.shape}")
        print("=" * 15)
        return (class_features, class_labels)

    # Caso normal: ambas as listas tÃªm dados
    class_features = np.array(class_features)
    no_class_features = np.array(no_class_features)

    class_labels = np.array([0] * len(class_features))
    no_class_labels = np.array([1] * len(no_class_features))

    # Concatena features e labels ao longo do eixo das amostras (axis=0)
    features = np.concatenate((class_features, no_class_features), axis=0)
    labels = np.concatenate((class_labels, no_class_labels), axis=0)

    print("=" * 15)
    print(f"Specialist summary for class {specialist_class}")
    print(f"Class features shape: {class_features.shape}")
    print(f"Class labels shape: {class_labels.shape}")
    print(f"No class features shape: {no_class_features.shape}")
    print(f"No class labels shape: {no_class_labels.shape}")
    print(f"Final features shape: {features.shape}")
    print(f"Final labels shape: {labels.shape}")
    print("=" * 15)

    return (features, labels)

def build_specialist_set_for_many_classes(features_set, labels_set, specialist_classes):
    specialist_sets = []
    for specialist_class in specialist_classes:
        specialist_set = build_specialist_set(features_set, labels_set, specialist_class)
        specialist_sets.append(specialist_set)

    return specialist_sets

def train_specialists(base_model, train_func, specialist_sets, class_names, model_name="Specialist", k_folds=5, verbose=False):
    """
    Treina modelos especialistas para cada classe usando conjuntos jÃ¡ preparados.
    
    Esta funÃ§Ã£o utiliza uma abordagem de "treinamento assistido" onde cada especialista
    Ã© avaliado usando validaÃ§Ã£o cruzada e depois treinado no dataset completo da classe.
    
    Args:
        base_model: Modelo base jÃ¡ tunado para treinar (ex: GridSearchCV configurado)
        train_func: FunÃ§Ã£o de treinamento assistido que aceita:
                   - base_model: modelo para treinar
                   - X, y: dados de treino  
                   - title: nome do modelo
                   - k_folds: nÃºmero de folds
                   - verbose: mostrar detalhes
                   E retorna: (modelo_treinado, mÃ©tricas)
        specialist_sets: Lista com conjuntos (features, labels) para cada classe
                        specialist_sets[i] = (X_i, y_i) onde i Ã© o Ã­ndice da classe
        class_names: Lista com nomes das classes (ex: ["dogs", "cats", "lions"])
        model_name: Nome base do modelo para logs (ex: "KNN-LBP")
        k_folds: NÃºmero de folds para validaÃ§Ã£o cruzada (default: 5)
        verbose: Se True, mostra detalhes do treinamento. Se False, apenas resumo (default: False)
    
    Returns:
        list: Array de modelos especialistas treinados onde specialists[i] Ã© o 
              especialista para a classe i (class_names[i])
              
    Example:
        >>> specialists = train_specialists(
        ...     base_model=tuned_knn,
        ...     train_func=train_model_knn,
        ...     specialist_sets=sp_lbp_sets,
        ...     class_names=["dogs", "cats", "lions"],
        ...     model_name="KNN-LBP",
        ...     k_folds=5,
        ...     verbose=False
        ... )
        >>> # specialists[0] = especialista para "dogs"
        >>> # specialists[1] = especialista para "cats" 
        >>> # specialists[2] = especialista para "lions"
    """
    specialists = []
    
    print(f"ğŸš€ Iniciando treinamento de especialistas {model_name}")
    print(f"   ğŸ“‹ {len(specialist_sets)} especialistas para treinar")
    print(f"   ğŸ”„ ValidaÃ§Ã£o cruzada: {k_folds} folds")
    print(f"   ğŸ“Š Modo detalhado: {'Ativado' if verbose else 'Resumo apenas'}")
    print("-" * 60)
    
    for i, (features, labels) in enumerate(specialist_sets):
        class_name = class_names[i]
        specialist_title = f"{model_name}-Specialist-{class_name}"
        
        print(f"\nğŸ¯ Treinando especialista {i+1}/{len(specialist_sets)}: {class_name}")
        
        if verbose:
            print(f"   ğŸ“ Features shape: {features.shape}")
            print(f"   ğŸ·ï¸  Labels shape: {labels.shape}")
            print(f"   ğŸ“Š DistribuiÃ§Ã£o de classes: {np.bincount(labels)}")
        
        # Usa a funÃ§Ã£o de treinamento assistido fornecida
        try:
            specialist_model, metrics = train_func(
                base_model=base_model,
                X=features, 
                y=labels,
                title=specialist_title,
                k_folds=k_folds,
                verbose=verbose
            )
            
            # Adiciona o modelo treinado ao array de especialistas
            specialists.append((specialist_model, metrics))

            if not verbose:
                # Mostra resumo compacto se verbose=False
                f1_mean, f1_std = metrics['f1']
                acc_mean, acc_std = metrics['accuracy']
                print(f"   âœ… Especialista {class_name} treinado!")
                print(f"      ğŸ“ˆ F1: {f1_mean:.3f} Â± {f1_std:.3f} | Acc: {acc_mean:.3f} Â± {acc_std:.3f}")
            
        except Exception as e:
            print(f"   âŒ Erro ao treinar especialista {class_name}: {str(e)}")
            raise e
    
    print(f"\nğŸ‰ Treinamento de especialistas {model_name} concluÃ­do!")
    print(f"   âœ… {len(specialists)} especialistas treinados com sucesso")
    print("   ğŸ“¦ Array retornado: specialists[i][0] = especialista para classe i")
    print("   ğŸ“Š MÃ©tricas de avaliaÃ§Ã£o: specialists[i][1] = mÃ©tricas do especialista para classe i")
    print("=" * 60)
    
    return specialists